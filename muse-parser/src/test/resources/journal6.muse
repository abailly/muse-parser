#title OQube's Blog
#author Arnaud Bailly
#description Random things I am working on...
#link http://localhost:4444/journal/journal

* 20081022: Valtech Days - Day 2

** Dojo refactoring legacy code

** Dojo randori sudoku

 - faire un plan ! **think** !
 - exposer les problèmes potentiels, les trous des exigences (contrats
   ou comportements attendus) le plus tôt possible

** Enterprise Agile (Jeff McKenna)

 - lot of low-level things, interested in what's going on at the
   enterprise level, *agile adoption*

**list of topics:**
 - could we avoid involving the client ? Old-school clients, PM acting
   as the client surrogate (ie. Product Owner)
 - agile team within non-agile organisation
 - role of QA in agile
 - how to become an agile enterprise
 - can the whole organization be agile 
 - what is an agile enterprise
 - convincing people to switch to agile process ? (eg. switching part
   of the team, other part *against* agile and how should we convince
   them) 
 - timeframe for transitioning
 - steps for adoption to agile
 - building up on the success of a pilot project
 - how to stay agile
 - agility: now what ?

voting: -> *Arguments to convincing*
 - usual voting scheme is to vote *for* and *against*

*** Arguments for convincing

**What's worked ?**
 - *trust me*, expert point of view
 - see the results quickly, readjusting quickly
 - first, acknowledge pain and unexpensive experiment
 - identifying a pilot (implies people are already convinced)
 - *demonstrate*: just do it ! make the metrics visible
 - bring in the experts

 - you cannot convince someone if they don't want to be convinced
 - you need to acknowledge pain
 - the more you are pushing your arguments, the more you find
   resistance
 - fear, change

 - interview each person at start of project, require agreement from
   the people (10-20% don't want to do it)
 - problem is at middle-management level, jobs more threatened than
   the "troops", need commitment from management
 - useful for convincing management is detailing each XP practices and
   its advantages 
    - CI allows bug detection early
    - Collective Code ownership allows any people to work on any part
      of the code
 - *Resistance as a resource*, Dale Emery: listening to resistance,
   extracting information, something will happen

cf Guitart, **"l'envie de s'y mettre"**

*** Agile team inside non-agile organization

 - organization as to willing to look at itself, being conscious,
   *learning organization*, retrospective is a tool to lear
 - start measuring something and show the data: ratio of working to
   add feature vs. working to fix bug
 - organizations need to be conscious of what's going on

 - managers are starting to lose control on people, they are
   disturbed, losing/keeping control
 - about changing organization, not agile

** Programming languages

Paul Graham in *Hackers and Painters*: "Language matters, and LISP is
the best one because of macros/meta-programming and its sheer rarity."

 - *question*:
    - what language do you use daily
    - what languages do you know
    - what language do you prefer
 - languages categories: scripts, compiled, interpreted,
   strongly-typed, dynamic typing, functional, object-oriented, ... 
 - why do you prefer that language

** Programmation Postmoderne

 - *modernisme* et *pré-modernisme*: Hegel, Kant, le sens de l'histoire
 - *narratives*: justification par le futur, ce qui doit/peut arriver,
   grandes histoires, valeurs fortes

* 20081021: Session sur les langages

 - La question du langage de programmation est intéressante et
   difficile. Tout le monde s'accorde pour dire que certains langages
   sont mieux que d'autres, généralement en restreignant le *meilleur* à
   un champ déterminé pour lequel ce langage s'est révélé
   particulièrement adéquat (ou a conquis une part de marché
   conséquente). Néanmoins, quand il s'agit de rentrer dans le détail
   et:
     1. de classer les langages, et 
     2. de définir des critères la plus largement possible acceptés
        pour produire ce classement,rien ne va plus
 - L'absence de consensus signifie que chacun tient à *son langage*
   préféré, pour des raisons diverses, et que cette appropriation
   relève de *l'acte de foi*, de la croyance
 - la foi est le produit d'une *révélation* ou d'une *pratique*, et bien
   plus souvent des deux: "Priez et vous croirez !" plutôt que "Croyez
   et vous prierez !"
 - de même qu'il est impossible de classer les religions en fonction
   de la foi, il est impossible de classer les langages en fonction
   des programmes qu'ils permettent d'écrire
 - les seuls critères de classement possibles sont nécessairement
   externes: nombre de développeurs, volume de code produit
   globalement, nombre de projets "échoués" avec ce langage, nombre de
   projets "réussis", nombre d'offres d'emplois...
 - ces indicateurs externes, d'ordre statistique, sont le produit de
   comportements individuels qui *eux* sont produits par des croyances,
   soit directes, soit indirectes
 - on a donc un système auto-référentiel: un langage est meilleur
   qu'un autre parce que les gens pensent qu'il est meilleur, et les
   gens pensent qu'il est meilleur parce que d'autres personnes le
   pensent 
 - cette situation masque la *vérité* de tout classement des langages,
   qui est que celui-ci est nécessairement contextuel: certains
   langages sont meilleurs que d'autres localement (selon telle et
   telle dimension), mais jamais globalement
 - la "valeur" d'un langage peut ainsi être vue comme la "valeur" d'un
   *actif* sur un *marché* (assez peu volatile)
 - cette valeur est déterminée par une relation  de proportion entre
   un *risque* (en l'occurence, le risque de ne pas satisfaire les
   utilisateurs) et une *rentabilité* (la rapidité avec laquelle
   l'application sera développée, le nombre d'utilisateurs,...)
 - la valeur d'un "systéme" est alors dans ce modèle la valeur d'un
   "portefeuille" d'éléments du système
 - l'absence de *liquidité* du marché limite considérablement le modèle,
   probablement au niveau d'une métaphore: on ne peut pas
   instantanément échanger des applications comme on échange des
   actifs financiers
 - néanmoins, ce modèle peut être utile et est utilisé comme outil de
   décision

* 20081021: Valtech Days - première journée

** En vrac

 - pas mal de monde, dont quelques suspects usuels retrouvés avec
   plaisir
 - une rapide discussion avec Sadek à propos d'Haskell, il faudra
   poursuivre demain si le temps nous le permet
 - j'ai déjà proposé deux sujets pour l'OpenSpace de demain, un sur la
   *Programmation fonctionnelle* et un autre sur les *langages de
   programmation*

** Programmation concurrente

Session présentée par Julien Delhomme, consultant chez Valtech, sur
les différents modèles de concurrence et l'avenir de ce type de
programmation pour le commun des mortels. Plusieurs modèles ont été
présentés:
 1. processus multiples et mémoire partagée (eg. Java), le modèle
    standard, le plus bas niveau et le plus compliqué à programmer
 2. vectorisation du code (eg. OpenMP), plutôt que parallélisation. On
    produit des calculs concurrents isolés 
 3. mémoire transactionnelle (*Software Transactional Memory*,
    eg. Haskell) 
 4. passage de messages (eg. Erlang)

 - quels outils pour aider à la programmation concurrente ?

** Dojo - Kata Mastermind en Ruby
Kata présenté par Emmanuel Gaillot et Etienne Charignon, sur le théme
du Mastermind. Excellente préparation, avec un bon déroulé du problème
et un gros effort d'explication de la part du copilote et du
pilote. La solution obtenue est effectivement assez élégante, encore
que l'on aurait pût - *dût* ? - remanier le code plus tôt de manière à
introduire les abstractions objets plus facilement (eg. le comptage
des jetons bien et mal placés).

Questions intéressantes sur:
 - l'apport du dojo pour ses participants: acquisition de réflexes,
   découverte de nouveaux langages, habitude de la programmation
   collective et en public (sous le regard d'autrui),
 - le degré de *tolérance* pour le remaniement,
 - l'applicabilité à des problèmes concrets d'entreprise.

* 20081021: Web application - Part 4 - Thinking

I have (nearly) the skeleton of a working web application in Haskell,
using FastCGI interface, storing session in a map keyed by some
integer value, and allowing users to login, register, logout... The UI
is pure HTML with javascript based on jQuery and its rich API: data is
requested from the server that is supposed to return javascript or
JSON objects, which will be used by the client side to update the
UI. This last part is still missing, but I am feeling I have reached,
once again, some dead end.

The structure of the application is embedded within the services it
exposed, meaning that, for example, that =register= updates the session
to allow =login= action, which in turns update the session to allow
=logout=  and =unregister=, etc. As those functions work on with a
database, this implies that to both work with I/O and with the state
of the application, they must work within a StateT monad transformer
parameterized with IO monad. We can foresee that composing additional
behavior will entail more and more monad stacking for eg. logging, error
tracking.

What we really is, as usual, **decouple** the various components and
layers we are working with so that each function serves one and only
one purpose and that the top-level application orchestrates them. At
this stage, without thinking about additional monadic behaviours, we
would like to distinguish at least two layers:
 - the *functional* layer exposing **stateless services** as functions,
   which in turn may be of two kind:
     - IO functions,
     - and pure functions,
 - the *applicative* layer that orchestrates the *availability* of
   functions according to some **stateful** computation, representing as
   usual the state of the interaction between the client and
   server.

Being a very flexible language, Haskell should allow us to express
composition of fucntions and behaviours externally, without the
individual elements ever noticing they are part of some composite
application. What is done with XML configuration files in Spring-like
frameworks should be done in Haskell within the Haskell framework.

This idea I have already implemented in Java while developing the
M-Commerce framework, which used an underlying finite-state machine to
orchestrate access to service and the Pico container framework for
dependency injection. DI within Haskell can be done:
 - at the module (linking time) level, by importing/exporting the
   right modules according to the configuration we want,
 - at the function level, by composing needed functions with
   compatible types,
 - at the type level, by constructing new types from existing types
   according to the needs.


* 20081020: Dojo Paris 

**Sujet**:
 - kata RoR, présentation du framework

 - scaffolding: initialisation des différents composants du systéme,
   génération des active records
 - notion  de *migrations*, scripts d'initialisation/terminaison de la
   base de données, exécuté par =rake= journalisé et versionné

* 20081020: Pattern-matching with functions only

While researching a way to represent pattern-matching easily within
the *My Language is Bigger than Yours* boardgame, I came upon a book
chapter on google-books that precisely defines a program
transformation for eliminating pattern-matching and recursive
data-types definitions from Haskell progras, thus making them composed
only of functions and primitive constants.

The key to this transformation is to observe that any datatype can be
equivalently transformed, using what is called *Church-encoding* into a
set of constructor and desctructor functions. This I have already
shown in a preceding article (see [[journal#-20081002--From-data-to-functions-and-back-][this article]] ). Given the following
data-type for binary trees:

<src lang="haskell">
data Tree a = Leaf a
            | Node a (Tree a) (Tree a)
</src>

we can define the constructor functions:
<src lang="haskell">
type Tree a = ((a -> c) -> (a -> t -> t -> c) -> c)
Leaf a      = (\l n -> l a)
Node a t t' = (\l n -> n a t t')
</src>

If we want to know the value stored at a tree, we can either write,
using pattern-matching:
<src lang="haskell">
value Node x     = x
value Leaf x _ _ = x
</src>
or, using constructor functions:
<src lang="haskell">
value t = t (\a -> a) (\a  _ _ -> a)
</src>

The key insight to this transformation is to notice that:
 1. each term of the sum of an algebraic datatype is basically a function
    that produces a type given some arguments, and
 2. an algebraic data type can be viewed as a *selector* function that
    discrimates between various possible behaviours according to its
    internal structure.

So we can hopefully generalize this transformation to *any* datatype:
given a type defined as a sum of products as:
<src lang="haskell">
data Type = Ctor1 p11 p12 ... p1n
          | Ctor2 p21 ... p2m
          | ...
          | Ctork pk1 ... pkl
</src>

we can define the type Type and a set of constructor functions =ctor1, ..., ctorl= defined
as:
<src lang="haskell">
type Type = (t11 -> ... -> t1n -> c)
         -> (t21 -> ... -> t2m -> c)
         -> ...
         -> (tk1 -> ... -> tkl -> c)
         -> c

ctor1 v11 ... v1n  = (\ f1 f2 .... fk -> f1 v11 ... v1n)
ctor2 v21 ... v2m  = (\ f1 f2 .... fk -> f2 v21 ... v2m)
...
ctork vk1 ... vkl  = (\ f1 f2 .... fk -> f2 vk1 ... vkl)
</src>
and then each function operating on =Type= that wants to pattern-match
against its instances should be implemented by passing the specialized
function to the given instance of Type that it is passed.

This can be generalized to n-ary pattern matching in the obvious way,
ie. by currying.


* 20081018: Filtering sections from Muse RSS Feed

It took me quite a few hours to implement a feature that, at first
sight, appears quite simple: *Extract and display a single entry from a
log file as an HTML page*. This feature is meant to be used as the
target of links from RSS feeds. Given the unexpected difficulty of the
task, and the somewhat contorted solution I found, I felt it would be
worthwhile to provide details of the problem, the various paths I took
and the (partial) solution I found.

** The context

I am developing a set of *Java* components based on the **Emacs Muse**
publishing format, a simple wiki-like text format that I discovered
a few years ago while using EmacsPlanner tool. Among other things,
this blog and the whole OQube's site are written in Emacs Muse and
published on the web using a dedicated web application.

This system is composed of, among others, the following components:
 - a parser, this is of course the core element of the *Muse-in-java*
   system. The input is analyzed and transformed into calls to a
   *MuseSink* instance, an interface somewhat like the SAX
   ContentHandler interface (actually, among other improvements, I am
   planning to replace this specialized interface with true SAX
   interfaces), 
 - various specialized backends, ie. implementations of the MuseSink
   interface, that produces other formats: XHTML, Trac wiki syntax,
   RSS 2.0 feeds and a copycat Muse format producer,
 - specialized *publishers* for each format, that handle the
   nitty-gritty details: reading files, setting input and output
   encoding, headers and footers definition...
 - a web application based on simple servlets that publishes one or
   more directories containing muse files as a web site in HTML and
   RSS formats, together with associated image and other files.

** The problem

The Feed backend produces a RSS 2.0 formatted news feed from a muse
file: Each level one title is considered a news item if the title
contains a date formatted as YYYYMMDD. In the RSS 2.0 format, each
entry is identified with a supposedly unique URI, which is formed by
transforming the date to =YYYY/MM/DD= format and suffixing it with the
title from which all non-ascii characters have been escaped (I should
use the standard =urlEscape()= function).

For example, *this* news item is transformed to:
<example>
<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/" version="2.0">
  <channel>
    <title>OQube's Blog</title>
    <link />
    <description>Random things I am working on...</description>
    <dc:creator>Arnaud Bailly</dc:creator>
    <item>
      <title>Filtering sections from Muse RSS Feed</title>
      <description>20081018: Filtering sections from Muse RSS Feed 
&lt;h2&gt;The context &lt;/h2&gt;
&lt;p&gt;I am developing a set of &lt;em&gt;Java&lt;/em&gt; 
      <pubDate>Fri, 17 Oct 2008 22:00:00 GMT</pubDate>
      <guid isPermaLink="false">http://localhost:4444/journal/journal/2008/10/18/Filtering-sections-from-Muse-RSS-Feed</guid>
      <dc:date>2008-10-17T22:00:00Z</dc:date>
    </item>
...
</example>

The problem lies in the =<guid>= tag: Using the given URI in a browser
should provide the given news in XHTML format. The news item should be
*extracted* from the muse file which contains all the news. The question
is: how to extract the selected news (or any other subset of the file)
from the muse file and format it ?

Abstracting away from the details, this problem can be narrowed to the
following: *Given a stream of objects, how to select a subset of this
stream using simple rules ?* For example, if we consider a stream of
=a-z= letters, we want to select the substream that is contained between
the letters =ab= and the letters =yz=. Applying this rule to the word
=jlkjlkabcdeffdsfyzflsfdkj=, we obtain the word =abcdeffdsfyz=.

It is obvious that, in the case of letters, this problem boils
down to regular languages matching: extract some rational pattern from
a stream (ie. a word). But in the case of events, we are facing a
somewhat different problem: the alphabet is infinite which implies the
language is not regular. Furthermore, writing a  finite state machine
ie. a regular language acceptor, while not an extremely complex task,
is not immediate and quite error-prone.

** The (path to the) solution

The idea I explored is based on *event filtering* and the *Decorator
pattern*: 
 - a *MuseSink* instance wraps the target sink and is set as backend for
   the publisher for HTML,
 - it passes *SinkEvent* instances, to
 - its *SinkFilter* instance =filter()= method which returns whether or
   not the event should be filtered,
 - if the answer is true, then the wrapper sink passes the event to
   the real sink.

The problem I faced was managing the state of the underlying FSA so
that parsing events can be passed in a timely fashion:
 - if a filter starts with a sequence of events, then it needs to
   buffer the accumulated events until they match the required
   pattern, 
 - but this implies that the sink:
    -  either knows when the pattern match, and then knows how to
       extract the accumulated events to be passed to the sink,
    -  or delegate the passing of events to the filter.

Neither of this solutions is satisfying:
 - the first one is too complex and breaks the *Single Responsibility
   Principle* and encapsulation by making the sink dependent on the
   precise implementation of the filter,
 - the second one also breaks the SRP and produces filters *non
   composable*.

** The choosen solution

The idea is to define the filter as a *SinkEvent* transformer, a
function from *SinkEvent* to *SinkEvent* that returns the event to be
passed to the real sink. A special event is defined, *NullEvent* that is
a *non-event* and, when asked to activate a sink, does nothing.  By
defining filters as transformers, they can be *composed*. 

<src lang="java">
public interface SinkFilter {
  SinkEvent filter(SinkEvent e);
}
</src>

Filters are then made into *combinators* that operate on stream of sink
events and, together with filter operators, can form a whole algebra
of stream transformers and selectors.

For this to works, I also needed to create a *CompoundEvent* object that
implements the *SinkEvent* interface and that passes all accumulated
events to its underlying sink. This is needed because, when the
filter needs more than one event lookahead, it buffers the events
passed so far and it cannot produce the correct event before having
matched the whole pattern. 

<src lang="java">
public interface SinkEvent {
  SinkEvent NULL_EVENT = new SinkEvent() {...};

  void passTo(MuseSink sink);
}

</src>

The interesting thing about a combinator-based implementation is
that, being in essence purely functional, it has a number of
interesting properties:
 - filters can be easily composed on the fly, 
 - properties can be stated and "proved" more easily than with an
   object-based hierarchy based implementation,
 - code is more compact.

The current implementation suffers however from some defects and is
not fully *functional*:
 - it is not *pure*, in that some filters maintain an internal state for
   matching several events,
 - negation is not properly implemented. A basic property that it
   should respect can be stated (in Haskell-like notation):
<src lang="haskell">
double_negation_property :: (SinkEvent -> SinkEvent) -> Bool
double_negation_property f = not . not . f == f
</src>
   but this does not work as a simple test using a =StartFilter=
   combinator can easily shows: 

Actually, one would like filters to be much like a boolean algebra,
closed under the usual operators: negation, intersection, union,
difference, much like lists are in most functional languages, and like
rational languages are.

* 20081015: Agile Tour 2008

Ça y'est, l'Agile Tour 2008 est passé par Lille ! En voici un bref
résumé, plus quelques idées pour une prochaine manifestation. 

** Les sessions 

Nous avons eu pas mal de désistements, mais il faut dire que nous
n'avons vraiment pas assuré côté relance: un mail tardif et une
relance téléphonique la veille pour le lendemain. Seuls les gens que
François et moi connaissions personnellement sont finalement
venus. 

Les sessions proposées étaient donc les suivantes:
 1. *Introduction à l'agilité*, par François Wauquier
 2. *Les projets Agile - de la réponse aux appels d'offres à la
    maintenance - retour d'expérience*, par Oana Juncu, et 
 3. *La démarche Agile: contexte favorable/défavorable*,
 3. *Pratiques d'ingéniérie incrémentale*, par Eric Mignot et Laurent
    Cobos, ainsi que  
 4. *Spécifications exécutables avec GreenPepper*, et
 5. *Dojo Randori*;
 4. *L'art du jonglage avec les pratiques XP pour le développement web
    / PHP*, par Perrick Penet
 5. *Opentime et ses 10000 tests automatisés*, toujour par Perrick,
 6. *Intégration continue & Offshore*, par Thomas Recloux,
 7. *Eclipse + Mylyn : Se concentrer sur une tâche*, par Dimitri Baeli,
 8. et un atelier de *Planification Agile* par Patrice Petit.

Les sessions étaient découpées en créneaux de 30', plus 5' de temps
élastique permettant de laisser aux gens de bouger.

Comme nous n'avions pas plus de sessions que de créneaux (18 au
total), les participants ont "voté" en arrivant avec des gommettes
pour nous permettre de répartir au plus juste les salles. La
répartition des votes semblait indiqué en grand besoin d'information,
plutôt que du pratiques, probablement parce que beaucoup de
participantsn n'étaient pas des experts de l'agilité et venaient là
pour découvrir, apprendre et surtout discuter. 

J'ai fait le planning après avoir introduit Agile Tour et les grandes
lignes de l'organisation, tandis que les orateurs se présentaient, eux
et leurs sessions. 

** Les lieux

Nous avions donc trois salles: 
 - un grand amphi d'une centaine de places;
 - une grande salle de réunion pour 30 personnes environ;
 - une petite salle de cours d'une quinzaine de places.

Les locaux de TELECOM Lille 1 sont très bien, mais la disposition des
salles, très éclatées les unes des autres n'étaient pas
idéale. Heureusement, le fléchage était bien fait et les salles quand
même situées dans des endroits évidents, pas au fin fond d'une
aile. Personne ne semble s'être perdu, ou du moins pas suffisamment
longtemps. 

** Les participants

Il y avait 85 inscrits, et il me reste 22 badges, donc j'en déduis
qu'il y avait au moins 63 participants. EN réalité, il devait y en
avoir légèrement plus puisque des gens non inscrits se sont présentés
spontanèment. 

Les profils étaient très variés. Je n'ai pas de statistiques précises,
dont le sens sur un échantillon de 60 personnes serait de toute façon
douteux, mais j'ai perçu les grandes lignes suivantes:
 - pas mal de développeurs,
 - quelques managers, chefs de projets, DSI. Peu nombreux mais
   intéressés par le sujet et demandeurs de billes pour faire
   progresser l'agilisme dans leur structure,
 - peu d'étudiants m'a-t'il semblé,
 - des belges en nombre relativement important. Perrick m'a dit avoir
   fait passer le message (je regrette d'autant plus le forfait de
   Pascal et Yves Hanoulle).

** Le déroulement

Tout le monde a salué l'organisation de l'événement, ce qui ne laisse
pas de me surprendre car j'ai vraiment eu l'impression qu'on a fait ça
à l'arrache et que c'était un peu... chaotique. Je pense, cela dit, que
beaucoup ont apprécié le côté *informel*. Le groupe était de petite
taille, la manifestation de courte durée et le lieu compact, donc
l'improvisation pouvait suppléer à la préparation.

Je n'ai eu que de bons échos, aussi bien de la part des participants
que des orateurs. Il faudrait avoir dépouiller les questionnaires de
satisfaction pour en savoir plus. J'ai le sentiment que tout le monde
a trouvé ce qu'il venait chercher ou a pu dire ce qu'il avait à dire. 

Je regrette un peu le manque d'ateliers et la faible participation au
dojo présenté par Eric Mignot et Laurent Cobos. Il me semble pourtant
de plus en plus que le développement de l'agilisme passe par là, que
c'est un outil extraordinaire pour progresser et faire
progresser. Comme si beaucoup de gens avaient un peu peur de se mettre
en danger en codant collectivement, comme si le code était toujours
quelque chose que l'on faisait solitairement.

** Des idées pour plus tard

J'ai vraiment envie de trouver d'autres formes que la classique
conférence où l'on vient écouter la bonne parole, confortablement
assis dans un amphithèâtre. Il me paraît essentiel, partie intégrante
des valeurs et des principes de l'agilité, que les participants
contribuent activement au contenu de la conférence. 

Les ateliers sont un bon moyen de parvenir à ce résultat, et en
discutant avec Marie-Aimée, nous avons imaginé d'autres types
d'organisation:
 - un débat modéré en amphitéâtre avec filmage en direct. Un
   facilitateur transmet le micro, donne la parole. Un cameraman cadre
   les interventions qui sont visibles immédiatement dans la salle et
   dans le forum. Des *orateurs* ou experts sont répartis dans la salle,
   pour éviter la séparation introduite par la scène. 
 - un montage en direct des ateliers et sessions filmées. Toutes les
   sessions sont filmées et directement mixées et montées en régie,
   pour être projetées dans le forum,
 - la mise à jour en direct d'un site web avec photos, vidéos,
   scannages de paper-boards et de notes, interventions et blogs des
   participants et orateurs. Un CD est réalisé à la fin de la
   conférence contenant le site et le contenu produit
 - l'utilisation d'un moteur d'analyse sémantique pour relier,
   regrouper et indexer les interventions sur le site.
 - le site de la conférence pourrait être mis  à jour par différents
   canaux: twitter, RSS, mails, blogs...


* 20081015: On code quality and TDD

An old post by [[http://michaelfeathers.typepad.com/michael_feathers_blog/2008/06/the-flawed-theo.html][Michael Feather]] that talks about things I would like to
present at SPA2009: different approach to code quality than TDD. Here
it talks about the Clean Room method that, back in the 80's, enforced
quality through formal expression of code behavior with logical
predicates (presumably Hoare's logic predicates).

* 20081009: Web application - Part 3

Things are getting more and more complicated as I am closing in on the
client-side of the web app. Thanks to some help from the
[[http://article.gmane.org/gmane.comp.lang.haskell.cafe/46016][haskell-cafe mailing list]] denizens,  I managed to got a running
FastCGI web application working, with the shared state passed around,
although this feature is untested.

The basic idea is to initialize the *World* once in a shared variable
reference, preferably a *thread-safe* one, then to pass that value to
the worker functions that could well be some IO threads. 

<src lang="haskell">
main = do world <- newTVarIO initialState  -- initialize shared variable containing state
          runFastCGI  $ work world         -- service requests 

work :: TVar World -> CGI CGIResult
work world = do sid    <- fmap (maybe 0 id) $ readInput "sessionId"      -- extract session identifier
                sname  <- fmap (maybe "index" id) $ getInput "service"  -- extract service name
                world' <- liftIO $ atomically $ readTVar world                     -- extract state of the world
                setHeader "content-type" "text/plain"
                output $ service sname world'
</src>

I am presently struggling with the client side, trying to use [[http://docs.jquery.com/][jQuery]]
and its [[http://malsup.com/jquery/form][Form plugin]]. I found the hard way that although they are
somewhat equivalent, and sometimes use equivalently in HTML, **id** and
**name** are not the same. jQuery selectors use *id* while form submission
uses the *name* attribute. So one usually define both or use
<code>[name='toto']</code> selector to extract the needed  field. 

I am still stuck with the intricacy of submitting forms, between
the subtleties of =submit()=, =ajaxForm()= and =ajaxSubmit()=, but I can now
pass around values from the client to the server, and most notably the
requested service and probably the session id if it is defined. 

I plan to make the application in client/server architecture, with the
Haskell code providing services and JSON data, and the client code
using jQuery to update the UI.

* 20081007: State Transformers again

I managed to refactor the code to use explicitly =State= and =StateT=
monad, thanks to [[http://www.haskell.org/pipermail/haskell/2005-March/015540.html][this thread]] on Haskell-café and this [[http://sigfpe.blogspot.com/2006/05/grok-haskell-monad-transformers.html][blog]] post. In
the process I got to understand a few things about those dreaded
monads and the way to combine them, although this obviously only
scratch the surface of things.

The code of authenticate now looks like:
<src lang="haskell">
getUser :: String -> String -> IOWorld (Maybe User)
getUser login password = lift $ readResource (User login password)

authenticate :: String -> String -> IOWorld (Maybe Session)
authenticate login pwd = do u <- getUser login pwd
                            liftState (createSession [("unregister", unregister),("logout", logout)] 
                                       (checkPassword u))
</src>

All top-level actions are done in the =IOWorld= context which is a
State monad encapsulating IO monad. We need IO because we are dealing
with the persistence layer.

The tests look a lot nicer, although some duplication obviously
persists:
<src lang="haskell">
aLoggedInUserCanUnregisterWithKey =
    "Logged in user can access unregister action with key" ~:
          (withDB "test.db" 
               (evalStateT (do register "nono" "password"
                               Just session <- authenticate "nono" "password"
                               let Just action = lookup "unregister" (actions session)
                               action session
                               authenticate "nono" "password") initialState >>=
                   assertEqual "unexpected user" Nothing))    
</src>

The sequencing of actions that the monad allows - and imposes - is not
cluttered anymore by explicit arguments passing. The extraction of the
action could encapsulated too in a nice monadic action.  

The important lesson about monads is: **you can't mix apples and
oranges**. Monad sequencing is just a special kind of composition:
 1. simple functions $f: a \rightarrow b$ and  $g: b \rightarrow c$
    are composed using =.= operator, yielding function  $g . f: a
    \rightarrow c$, 
 2. functions with effects $f: a \rightarrow m b$ and  $g: b
    \rightarrow  m c$ (ie. functions within monads) are composed 
    using =>>= and <code>>>=</code> (ie. *bind*) operators, yielding
    function $f join g: a \rightarrow m c$.

The important thing to note is that both *encapsulated* type and *monad*
type have to be compatible (ie. the same) for this to work. One cannot
compose actions occuring in different monads without some kind of
*transformation* which is just why *monad transformers* are useful: they
allow one to unify different kind of actions/effects within a single
layered monads. 

One important function in this context is the =lift= operator that
allows, as it name implies, *lifting* functions operating within one
monad to another layer of monad. This means that given a  =IO a= action,
you can lift it to a =StateT s IO a= action by  lift, but given a =State
s a= action, how do you *lift* it to =StateT s IO a= ? You need to apply
the IO monad to the result of the  State monad before returning it. 

One solution given by the cited posts is to define a =liftState=
function:
<src lang="haskell">
liftState :: Monad m => State s a -> StateT s m a
liftState s = do state1 <- get
                 let (result, state) = evalState (do result <- s
                                                     state <- get
                                                     return (result, state)) state1 
                 put state
                 return result
</src>

But there is another, more elegant, solution: use the interface
[[http://www.haskell.org/ghc/docs/latest/html/libraries/mtl/Control-Monad-State-Class.html#t%3AMonadState][MonadState]] to constrain the context of the =createSession= function and
all other functions that operate at the state level and could need to
be lifted at some other level. We can thus now write:
<src lang="haskell">
createSession :: MonadState World m => [(String,Action)] -> Maybe User -> m (Maybe Session)

authenticate login pwd = getUser login pwd >>=
                         (createSession [("unregister", unregister),("logout", logout)] . checkPassword)
</src>

I can understand this barely but will try to explain it:
 - see [[http://thread.gmane.org/gmane.comp.lang.haskell.cafe/45634]] for details
 - we know that the return type of =createSession= must be some monad =m=
   that is also an instance of =MonadState=,
 - among the instances of =MonadState s m=, one finds =MonadState s
   (State s)= and =MonadState s (StateT s m)=, 
 - given that =authenticate= has return type =IOWorld a=, or more
   precisely that the right hand side of the equation for authenticate
   has this type, we know that monadic actions will take place within
   this monad (a type alias for =StateT World IO a=),
 - =getUser l p= has such a type, so we can *bind* its result **within** the
   monad to another monadic action,
 - =checkPassword= is a simple function that takes a =Maybe User=, 
   checks the supplied password is correct and returns the user or Nothing,
 - it is composed (using . as it is not monadic) with =createSession=,
   our MonadState dependent action. Thus the whole type of
   =(createSession ... checkPassword)= is <code>MonadState World m =>
   Maybe User -> m (Maybe Session)</code> which **is** monadic but with
   the monad as a parameter =m=, which is then instantiated with =IOWorld=
   an alias for  =StateT=.
 - QED: authenticating a user is the action that retrieves the user
   from the persistent store and, if user exists, checks its password,
   creates a session for it and stores the session in the *world*.

* 20081006: StateT monad transformers and IO

While working on Haskell implementation for Colivri, I got stuck
within the complexity of *monad transformers*, most specifically with
the wiring of the State monad with the IO monad. The code uses state
to store session informations when users log in and out of the
system. For example, the =authenticate= function looks like:

<src lang="haskell">
authenticate :: String -> String -> World -> IO (World, Maybe Session)
authenticate login pwd s = readResource (User login "") >>= 
                           return . (createSession s [("unregister", unregister),
                                                      ("logout", logout)] . checkPassword) 
     where
      checkPassword Nothing = Nothing
      checkPassword u@(Just (User uid pwd')) | pwd' == pwd = u
                                             | otherwise   = Nothing
</src>

The =StateT= is defined as

<src lang="haskell">
newtype StateT s m a = StateT (\s -> m (a,s))
</src>

so I am tempted to rewrite authenticate as:

<src lang="haskell">
type IOWorld a = StateT World IO a
authenticate :: String -> String -> IOWorld (Maybe Session)
</src>

The problem is that I am not able to write the code that would make
this to typecheck or compile !


Otherwise, I managed to write a simple command-line interface through
which I can login/logout and register/unregister users within the
database. Next step is to wire that logic through FastCGI. But how do
we maintain state on a FastCGI server ?

* 20081003: jsUnit and Callbacks

In a [[http://code.google.com/testing/TotT-2008-10-02.pdf][recent entry]] of *Testing in the Toilets*, a technique is described
for testing asynchronous handlers tied to =setTimeout= et al. family of
functions, available at the global scope. This is something I tried to
do in Benefit for the scheduling code of test executors, but much
better as here the passing of time is controllable. 

* 20081002: Web Application in Haskell  - Part 2

** Database

I spent part of the morning switching from flat file storage to DB
storage for the tiny little embryonic web app in Haskell I am working
on. I managed to use Sqlite3 bindings for [[https://software.complete.org/software/wiki/hdbc/][HDBC]] which is quite
low-level but at least works smoothly once you recall how to code in
SQL. 

Installation was easy once I removed the =.cabal= and =.ghc= directories
from my =$HOME=:
<example>
sudo aptitude install libghc6-hdbc-sqlite3-dev
</example>

I then made =User= type an instance of IResource and implemented the
CRUD operations there:
<src lang="haskell">
import Database.HDBC
import Database.HDBC.Sqlite3

...
handleError str err = error $ str ++ ":" ++ ( seErrorMsg err) ++ ", code:" ++ show (seNativeError err)

instance IResource User where
    keyResource User {login = uid} = uid
    writeResource User {login = uid, password = pwd} = 
        handleSql (handleError "in write resource") 
                  (do con <- connectSqlite3 "test.db"
                      run con "insert into auth_user (username, password) values (?,?);" [SqlString uid, SqlString pwd ]
                      commit con
                      disconnect con)
</src>

The rest of the code is unchanged as I have abstracted operations on
users using IResource interface. 

Unit tests are unchanged too, except for the *setup* and *tearDown*
methods which now respectively create the necessary table and drop the
table.

<src lang="haskell">
createtableuser = "CREATE TABLE \"auth_user\" ("++
                  "\"username\" varchar(30) NOT NULL PRIMARY KEY,"++
                  "\"password\" varchar(128) NOT NULL"++
                  ");"

setupDB fn = 
    (do con <- catchError "connectinig" (connectSqlite3 fn)
        catchError "creating tables" (withTransaction con (\con -> run con createtableuser []))
        catchError "disconnectinig" (disconnect con))
              
tearDownDB fn =
    (do con <- catchError "connectinig" (connectSqlite3 fn)
        catchError "dropping" (withTransaction con (\con -> run con "drop table auth_user;" []))
        catchError "committing" (commit con)
        catchError "disconnecting" (disconnect con))
</src>

The reason I am catching errors for each statement rather than
encapsulating everythnig at a higher-level is that I got strange error
messages at first which I spent an hour tracing. The message was
something like =unknown error in sqlite3...= and conducted to the base
being locked. It was actually caused by incorrect parameters for
statements: you don't need to put quotes around the =?= when the
expected parameter is a string.

So I am now ready to continue working on the business domain and
implement the book manipulation logic.

** Session handling 

I refactored the code to add session handling: a user is tied to a
session that is supposed to restrict the actions the user can do, and
the sessions are all part of some state object that is updated and
read by the various *interface* functions (ie. functions that
corresponds to actions in the application). 

The code is not very nice, with lot of redundancy as I pass along the
state object everywhere in the code instead of using it implicitly
through the [[http://www.haskell.org/all_about_monads/html/statemonad.html][State monad]].

This code should be replace by something less ugly:
<src lang="haskell">
-- session
differentUserHaveDifferentSessionKeys =
    "Log two users and check for session key" ~:
          (withDB "test.db" 
               (do st               <- register "nono" "password" initialState
                   st'              <- register "tutu" "pass" (fst st)
                   (st'', Just s1)  <- authenticate "nono" "password" (fst st' )
                   (st''', Just s2) <- authenticate "tutu" "pass" st''
                   assertBool "session key not different" ((key s1) /= (key s2))))
</src>

The idea is that the Session object should hold a  list of allowable
functions in the present state of the application. Later on, the
Session shall have a time limit attached which will be checked
periodically by some cleanup thread code.

In short, each session is a continuation for the current user, that
when applied some action yield another continuation until termination
of the interaction. The **Back button problem** is solved by defining the
set state space independently of the pages so that whenever a user
crosses some important threshold (eg. does some action that has a
side-effect in the world and is not idempotent), this action is simply
removed from the continuation. Getting back on the page and
reactivating the link yields to an error. 

OTOH, it may be possible that back is not a problem, if the state
includes several *views* embodied as pages. 

* 20081002: From data to functions and back

See this [[http://www.kennknowles.com/blog/2008/05/24/what-is-defunctionalization/][article]], cited from [[http://blog.plover.com/2008/05/31/#defunctionalization][Universe of Discourse]]  for an in-depth
explanation of how *data* types and *functions* are related in FP. A data
type is just a function type listing all constructors for the type.

<src lang="haskell">
type ChurchPair a b = (forall c . a -> b -> (a -> b -> c) -> c)

churchPair x y = (\operation -> operation x y)
churchFst  p   = p (\x y -> x)
churchSnd  p   = p (\x y -> y)
</src>

A pair is constructed (by =churchPair=) from two elements (=a -> b=) and is a function
that can apply a function of two arguments (=a -> b -> c=) to its two
constituents. Here =churchFst= and =churchSnd= are destructors that can
observe the values stored in the pair by *decapsulating* it. 

A robot whose coordinates are defined as =(x,y)= and which has a
direction can thus be modelled as the type:
<src lang="haskell">
type Robot x y d = (forall r . x -> y -> d -> (x -> y -> d -> r) -> r)

makeRobot x y d = (\obs -> obs x y d)
posX r          = r (\ x y d -> x)
posY r          = r (\ x y d -> y)
direction r     = r (\ x y d -> d)
</src>

* 20081001: First web application in Haskell

For project [[http://www.colivri.org][COlivri]], I am trying to create my first web application in
Haskell, using [[http://happs.org][HApps]] as a web application server and framework.

** Installation

Getting HApps built and installed is not straightforward, at least
when your GHC installation seems a bit broken as is my case (Ubuntu
Hardy Heron, GHC 6.8.2). It took me approximatively 1 hour to got the
first basic example compiled and running. Assuming a ghc compiler
available (in my case 6.8.2), the right way seems to be:

 1. Install cabal, following instructions at [[http://hackage.haskell.org/trac/hackage/wiki/CabalInstall][Hackage]]'s site
 2. Don't forget to update cabal's list of packages:
<example>
cabal update
</example>
 3. download HApps distribution following instructions on the site:
<example>
darcs get --partial --tag=0.9.2 http://happs.org/repos/HAppS-HTTP
cd HApps-HTTP
cabal install
</example>

This scenario implies that all packages got installed into
=$HOME/.cabal= directory. There should be a way of installing everything
system-wide, probably using some prefix command. 

I could not manage to start working with the HApps-Begin sample blog,
which actually seems outdated and is not referenced anymore in the
HApps main page. Looking at [[http://happs.org/repos/HAppS-HTTP/Examples/AllIn.hs][AllIn]] example is not really convincing
that HApps is, as advertized on the web page:

   A web framework for developers to prototype quickly, deploy painlessly, scale massively, operate reliably, and change easily.

** Using FastCGI

I am turning towards a more barebone approach using CGI scripts. The
idea anyway would be for the application to be structured as:
 1. static HTML pages providing basic layout and style
 2. Javascript for loading data and jQuery for manipulating the DOM
    and formatting everything
 3. Haskell CGI scripts as web services 

I decided to give a try to the approaches described [[http://mult.ifario.us/p/wiring-haskell-into-a-fastcgi-web-server][here]] and [[http://www.cs.chalmers.se/~bringert/darcs/hs-web-tut/][here]],
which is certainly cruder than using a web application framework but
at least everything in there I understand.

[[http://www.fastcgi.com/][FastCGI]] is a replacement for *Common Gateway Interface* protocol where,
instead of starting one new process for every invocation of desired
script, the scripts are kept running within the context of a server so
that there is no loading and linking time wasted. 

Installing FastCGI to run on apache 2.2 is easy:

<example>
sudo aptitude install libapache2-mod-fastcgi
sudo a2enmod fastcgi
sed -i -e '/<\/VirtualHost>/ i\
\
    Alias /hcgi/ /var/soft/hcgi/\
\
    <Directory /var/soft/hcgi/>\
        SetHandler fastcgi-script\
        Options +ExecCGI\
    </Directory>' /etc/apache2/sites-available/default
/etc/init.d/apache2 restart
</example>

This makes directory =/var/soft/hcgi/= a container for executable
FastCGI programs (they should have extension =.fcgi=).

Then I copied a simple echo program that outputs process and PID id
for each request:
<src lang="haskell">
import Control.Concurrent
import System.Posix.Process (getProcessID)

import Network.FastCGI

test :: CGI CGIResult
test = do setHeader "Content-type" "text/plain"
          setStatus 200 "OK" 
          pid <- liftIO getProcessID
          threadId <- liftIO myThreadId
          let tid = concat $ drop 1 $ words $ show threadId
          output $ unlines [ "Process ID: " ++ show pid,
                             "Thread ID:  " ++ tid]

main = runFastCGIConcurrent' forkIO 10 test
</src>

Compilation is:
<example>
ghc -threaded -package fastcgi --make -o info.fcgi info.hs
</example>

** Application development

*** Basic

I start by writing an authentication module. This module lets a user
authenticate itself on a form providing a login/password combination,
then lookup the user in some database. If the user is regristered,
then it receives main page of the application with the ability to
*logout*, otherwise it is show the login page again with an error
message.

I want to work using *continuations-based* forms, without relying on
cookies for user identification. All the information is stored in the
server using a *map* from tokens to *functions*. Tokens have an expiry
time which makes functions unavailable after a while. 

*** Storing resources

I found [[http://haskell-web.blogspot.com/2006/11/transactional-cache-for-haskell.html][this blog]] that shows how to implement persistence layer for
data objects *à la* Hibernate in Haskell. It describes a *Transaction
Cache* that stores allows CRUD operations for abstract resources mapped
to underlying persistence layer.

I try to implement a persistence layer using sqlite and colivri DB.

2008.10.01 18:24:28

I managed to implement login and registration logic, with unit tests,
using simple file system storing as I could not manage to find a working
HDBC sqlite3 driver to work. When trying to install the modules from
cabal, they would not compile, complaining about missing identifiers
which obviously is a problem. I may try to install them from sources
directly.

The code so far looks like:
<src lang="haskell">
module Colivri where
import TCache
import DefaultResource

data User = User { login :: String 
                 , password :: String }
            deriving (Eq, Show, Read)

instance DefaultPersistResource User where
    defKeyResource User {login = uid} = uid
    defPath User {}  = "users/"

authenticate :: String -> String -> IO (Maybe User)
authenticate login pwd = readResource (User login "") >>= 
                         return . checkPassword 
    where
      checkPassword Nothing = Nothing
      checkPassword u@(Just (User uid pwd')) | pwd' == pwd = u
                                             | otherwise   = Nothing


register :: String -> String -> IO (Maybe User)
register login pwd = readResource (User login pwd) >>= registerIfNotPresent 
    where
      registerIfNotPresent Nothing = do let u = (User login pwd)
                                        writeResource u
                                        return (Just u)
      registerIfNotPresent _       =  return Nothing
</src>

The =TCache= module provides a simple CRUD layer where objects are
stored with Show and retrieved with Read. This is actually a
limitation of the DefaultPersistResource which stores data in flat
files named by primary key. It should not be too complicated to
implement something else as IResource interface does not rely on
particular structure of data.

More interesting are the unit tests, partially shomn here:
<src lang="haskell">
import Control.Exception(bracket_)
import System.Directory(createDirectoryIfMissing,removeDirectoryRecursive)

setupDir :: FilePath -> IO ()
setupDir fn =
    createDirectoryIfMissing True fn 

tearDownDir :: FilePath -> IO ()
tearDownDir fn =
    removeDirectoryRecursive fn

withDirectory fn = bracket_ (setupDir fn) (tearDownDir fn)

unregisteredUserCannotBeAuthenticated =
    "Empty user tries to authenticate and fail" ~:
              (withDirectory "users" 
               (authenticate "" "" >>= assertEqual "user should not exist" Nothing))


registeredShouldBeAuthenticated =
    "Existing user tries to authenticate and succeeds" ~:
              (withDirectory "users" 
               (register "nono" "password" >>
                authenticate "nono" "password" >>= assertEqual "user exist" (Just $ User "nono" "password")))

registeredUserWithBadPasswordIsRejected =
    "Existing user tries to authenticate with wrong password and fails" ~:
              (withDirectory "users" 
               (register "nono" "password" >>
                authenticate "nono" "pass" >>= assertEqual "user exist" Nothing))

</src>

I found this [[http://www.jasani.org/2007/12/05/unit-testing-with-hunit-in-haskell][article]] very useful. it provided me the necessary
features to create setup and teardown methods. The key point is to
notice that =Assertion= actually produces an IO value, and thus can be
injected into IO monad code easily.

Here is a short list of resources I used today:
 - [[http://www.cs.chalmers.se/~bringert/darcs/hs-web-tut/]]
 - [[http://www.happs.org/]]
 - [[http://mult.ifario.us/p/wiring-haskell-into-a-fastcgi-web-server]]
 - [[http://www.jasani.org/2007/12/05/unit-testing-with-hunit-in-haskell]]
 - [[http://haskell-web.blogspot.com/2006/11/transactional-cache-for-haskell.html]]
 - [[http://www.haskell.org/haskellwiki/Cabal/How_to_install_a_Cabal_package]]
 - [[http://www.defmacro.org/ramblings/haskell-web.html]]
 - [[http://www.jasani.org/2008/02/03/haskell-hdbc-and-sqlite]]
 - [[http://software.complete.org/software/projects/show/hdbc]]
 - [[http://lukeplant.me.uk/blog.php?id=1107301663]]

* 20081001: The long tail

Some mathematical musing about the illusions of *normal distribution*
and how it affects our perception of *average*, even for that fraction
of a population which is being selected from the above average 

   http://blog.plover.com/2008/09/30/#right-skewed

It has some interesting consquences as far as programming and software
development is concerned, and I particularly liked this sentence:
 
   *That's an important thing to know about the sport, and about team
   sports in general: you don't need great players to completely
   clobber the opposition; it suffices to have players that are merely
   above average. But if you're the coach, you'd better learn to make
   do with a bunch of players who are below average, because that's
   what you have, and that's what the other team will beat you with.* 

Do not confuse the *average* with the *median* !

* 20080930: More work on site feed

Working on displaying links from the site feed. The idea is that a
link like =/journal/2008/08/08/some-title= should display only the
selected entry if it exists, respecting the overall page style  of the
site. The problem is: how to extract part of the file for markup ? 

The solution I came up with is to wrap the destination sink (usually
HTHL) so that it receives only events within the start and end of the
selected section. One obvious problem with this scheme is that
sectioning is not hierarchical. Titles are just like =hX= header tags in
HTML, they only denote some formatting change but not distinct
levels. This could be changed easily by embedding sectionning within
the muse parser, so that section state would last to next sectioning
or end of document, whichever comes first. 

It is then easy to select only the events that pertains to some
section as we can filter on the =start= event and then decide whether or
not to pass all events to wrapped sink.

Another solution is to accumulate the markup events and pass them to
downstream formatter only if selector's pattern is triggered.

* 20080929: Testing OQube web site

Started to write tests for OQube's site that could be run under CI to
ensure proper operation of the site. First test written is a spider
that checks all links collected from the web pages traversed by the
site. This test uses code from [[http://www.jeffheaton.com/source][Jeff Heaton]] web sites for a simple
spider. For the moment, it is sophisticated enough for my needs.

I ran into a problem reported [[http://forum.mediamaster.com/viewtopic.php?t=619&sid=7f3da85cdcce9b67ccc9c400e10e95bb][here]] while checking URL from Ubuntu web
site using HTTPS. Looks like Sun's default cacerts file is missing
some useful certificates.

I also want to setup some load and performance testing. The problem is
how to setup a meaningful test for such a thing ? I looked at various
tools for web application testing:
 - [[http://www.hpl.hp.com/research/linux/httperf/][HttPerf]] is a "simple" command-line oriented tool, running on
   various platforms from native code. It is simple to setup:
<example>
sudo aptitude install httperf
</example>
   and produces results like: 
<example>
$> httperf --hog --server www.oqube.net --num-conn 1000 --ra 70\
   --timeout 5
httperf --hog --timeout=5 --client=0/1 --server=www.oqube.net --port=80 --uri=/ --rate=70 --send-buffer=4096 --recv-buffer=16384 --num-conns=1000 --num-calls=1
Maximum connect burst length: 5

Total: connections 1000 requests 619 replies 619 test-duration 19.279 s

Connection rate: 51.9 conn/s (19.3 ms/conn, <=230 concurrent connections)
Connection time [ms]: min 119.9 avg 1229.7 max 4529.6 median 1209.5 stddev 868.4
Connection time [ms]: connect 636.6
Connection length [replies/conn]: 1.000

Request rate: 32.1 req/s (31.1 ms/req)
Request size [B]: 64.0

Reply rate [replies/s]: min 32.6 avg 40.7 max 45.6 stddev 7.1 (3 samples)
Reply time [ms]: response 590.6 transfer 2.5
Reply size [B]: header 172.0 content 1884.0 footer 0.0 (total 2056.0)
Reply status: 1xx=0 2xx=619 3xx=0 4xx=0 5xx=0

CPU time [s]: user 0.21 system 14.00 (user 1.1% system 72.6% total 73.7%)
Net I/O: 66.5 KB/s (0.5*10^6 bps)

Errors: total 381 client-timo 381 socket-timo 0 connrefused 0 connreset 0
Errors: fd-unavail 0 addrunavail 0 ftab-full 0 other 0
</example>
 - [[http://grinder.sourceforge.net/links.html][The Grinder]] is a more sophisticated tool written in Java, that
   provides a distributed load and performance testing architecture,
   together with scriptable sessions (in Jython), a console view, and
   various tools for analyzing results and produce graphs from it. 
 - will try to explore more at
   [[http://www.opensourcetesting.org/performance.php]] when given some time

Might have a look at [[http://webflange.sourceforge.net/]] too.

* 20080917: Interesting variation around Form validation problem

On a recent [[http://rickyclarkson.blogspot.com/2008/09/implementing-builder-pattern-in-java.html][post]], Ricky  CLarkson implements constraints on data
fields using a builder pattern: fields are declared using a
combination of filter (Parameter) objects that apply certain
constraints. Then an object is constructed with Builder pattern that
checks appropriate constraints and throws unchecked exception upon
error. 

* 20080909: Dojo de lundi

Un dojo inspiré de [[http://blog.tmorris.net/haskell-scala-java-7-functional-java-java][Tony Morris]]: comment analyser une chaîne de
caractères composée de paires de parenthèses et crochets équilibrés ?


* 20080909: Builder Tester agent

Started working on the **tester** agent, first laying out basic
infrastructure for executing JUnit tests: wrapping JUnitCore executor
so that test cases get detected by the framewok, while handling class
loading issues. 

Test executions is OK, both for failures and successes, but I suspect
reporting is rather lame. This shall be improved later on. My goal is
to reach rapidly a state where:
 - tests are automatically executed after succesful compilation,
   providing instantaneous feedback
 - only needed tests are executed depending upon the modified files:
   this will be maintained using openjgraph's dependency graph
   augmented with files dependencies
 - things are integrated into the graphical monitor
 - paths parameters can be configured easily using properties files at
   application's startup

* 20080904: Stateful closures in functional java

I read and compiled the code from
[[http://lucdup.blogspot.com/2008/09/closures-statefulness.html]] using
the latest java compiler integrating closures from [[http://javac.info]]. 

* 20080903: Handling CSV files for accounting purpose

I finally wrote a Haskell program for managing my ledger files and
producing raw data for my accountant. The problem is simple: I use
[[http://www.newartisans.com/software/ledger.html][ledger]] program for bookkeeping, which is basically a
flat text file containing all basic accounting transactions in
double-entry format (a transaction is valid iff all atomic writings to
its accounts sum up to 0, see
[[http://en.wikipedia.org/wiki/Double-entry_bookkeeping_system]]).

Ledger program can produces various outputs, most notably the *balance*
format, that outputs the net debit and credit value of each account
taking into account all transactions; and the *csv* format which is all
transactions as CSV, for easy inclusion in spreadsheets for
example. There is no debit or credit notion in ledger, only positive
and negative numbers. 

What I need is somewhat similar to CSV output, but with additional
requirements:
 - numbers must be posted to accounts as either *debit* or *credit*, with
   each category having its own column;
 - there must be  columns for cumulative debits and credits;
 - cumulative values must be grouped by accounts;
 - I want to check that the general balance of debits and credits is
   0.

So the basic steps for this is the following:
 1. parse the CSV input and create a list of transactions items, one
    for each line of the input. Each transaction item should contain
    the date, the account number and title, the debit or  credit
    amount ;
 2. sort this list by account number and date;
 3. group by account number;
 4. accumulate value for each group;
 5. output the items as CSV lines.

In short, we have the following structure for the main function:

<src lang="haskell">
makeGeneralLedger :: [String] -> [String]
makeGeneralLedger =
          (concatMap displayCsv) .
          (map (accumulate amountZero)) .
          groupByAccount .
          sort .
          (map parseRawCsvLine)

groupByAccount :: [TxItem] -> [[TxItem]]
groupByAccount = groupBy (\ t t' -> accountNo t == accountNo t')

accumulate :: Integer -> [TxItem] -> [TxItem]
accumulate acc [] = []
accumulate acc ((TxItem d c p l an al am _) : ts) = (TxItem d c p l an al am (addAmount am acc)) : accumulate (addAmount am  acc) ts


displayCsv :: [TxItem] -> [String]
displayCsv ts = (map displayTx ts) ++ [""]

displayTx :: TxItem -> String
displayTx (TxItem d c p l an al am ac) = concatMap (++ ";") [(show d)
                                                            ,an
                                                            ,al
                                                            ,"(" ++ p ++ ")"
                                                            ,l
                                                            ,(debcred am ";")
                                                            ,(debcred ac ";")]
</src>

=TxItem= is a record data type that contains all the necessary
information about a single transaction.

** Version 1: Parsec

The first version I wrote uses [[http://legacy.cs.uu.nl/daan/parsec.html][parsec]] library for parsing the
input. This is where I spent a lot of time, understanding how parsing
with combinators worked and making lot of mistakes, out of ignorance
and out of bad practice.

I tried to use TDD to do the parsing, which helped me a bit but did
not produce a lot of tests. Tests are painful to write, like:

<src lang="haskell">
canParseCSVTxItem =
    TestList [
              txItemParser txItem "\"2006/06/12\",\"Facture Norsys SAS\",\"706100:Produits:Services\",\"EUR-900,000000\",\"EUR-900,000000\",\"*\",\"F20060601\",\"\""
              ~?=
              Right (TxItem (toGregorian 2006 06 12) True "F20060601" "Facture Norsys SAS" "706100" "Produits:Services" (TxAmount Credit "EUR" 900000000) (TxAmount Credit "EUR" 900000000))
             ]
</src>

Main problems I had were:
 - understanding that a failed rule may actually consume input, thus
   preventing =<|>= rules to complete succesfully;
 - rules were just wrong, yet I was so immersed and trying to solve
   the problem quickly I could not see they were wrong (I missed a
   part of the rule, consuming a comma);
 - parser could not read easily euro signs, which I had to transform
   to =EUR= string. There seems to be well-known limitations or problems
   with the way Haskell handles UTF-8: although internally strings are
   lists of unicode characters, I/O is not so forgiving.
 - I used [[http://www.bortzmeyer.org/calculs-calendaires-en-haskell.html][Calendar]] package from Stéphane Bortzmeyer which is a nice
   and simple program to compute dates
 - I borrowed some code from [[http://sequence.complete.org/node/259][here]] to have parsec combinators that
   could handle correctly newlines and eofs. I actually had lot of
   troubles initially to handle *lines* and lines termination. This code
   seems to be the cleanest way to express the fact that a line is
   either terminated  by EOL or by EOF.
 - Conversion from/to strings and ints is somewhat painful and ugly in
   my code:
<src lang="haskell">
readInt :: String -> [(Int, String)]
readInt = reads
...
      let (ip,_):_ = readInt intpart
</src>
 - the code is very "sequential", but it is the nature of the parsing,
   a sequence of things.
 - I decided to read strings into a data-structure with Integer values
   for representing numbers, so that calculations should always be
   exact at the 6th decimal place. Using Integer instead of Int may be
   cumbersome as you need =toInteger= to transform everything. There
   seems to be a [[file:///usr/share/doc/ghc6-doc/libraries/base/Data-Fixed.html][Data.Fixed]] type that would be better suited but it is
   poorly equipped in terms of operators
 - I think the code is too complex for what I am trying to achieve:
   parsing CSV lines should be easier, maybe using regexp. Parsec is
   probably overkill for such a regular structure.

** Version 2 : Correct version 1

Developping version 1 I cut corners and it failed: The program
computed incorrect values. Two things that I did not take into account
where:
 - when reading decimal number into an Integer, the calculation is
   simply to scale the integral part by $10^6$ and add the decimal
   part. I overlooked the fact that the number of digits after decimal
   sign is variable, so one needs to scale it also according to the
   number of digits it has. This yielded incorrect numbers;
 - when *showing* the =TxAmount= data, I separate again integral and
   decimal part with =quotRem= then concatenate the two strings. But I
   did not take into account the fact that the decimal part could be
   lower than 10^6, which means its string represenation has 5 instead
   of the required 6 digits.

The interesting thing is that both errors are due to lack of
verification of those parts of the code that just do this
parsing, or in other words, I did not test enough my program before
shipping, or worse I did not developed it using TDD, which would have
hopefully revealed this problem before.

These problems are actually the two sides of the same coin, and what I
really need is asserting that:
 1. given any correctly formatted decimal string, I can parse it then
    show it again and it will be the same string plus maybe some added
    zeros at decimal place for padding,
 2. given any =Integer=, I can show it then parse it again and it will
    be the same value.

The real problem, of course, lies in the *any*: These properties should be
proved for **all** possible correct strings and all possible Integer
values, while my TDD tests cover only a fraction of the possible
values, selected for their representativity or their usefulness at the
time of writing the test. The devils lurks in the details, so I must
be careful while TDDing in choosing those values.

Quickcheck may help in solving those problems. I can express the two
above properties using Quickcheck:
<src lang="haskell">
roundtripOnInteger = forAll generateDecimal $ \d -> 
                          (right . parseDecimal . showDecimal) d == d

roundtripOnStrings = forAll generateCorrectStrings $ \s ->
                        let s' = trimStrings s
                        in  collect (lengthOfDecimal s') $
                            (showDecimal . right . parseDecimal) s' == s
</src>

The second one is a little more complex as we are verifying the
property for all strings where trailing zeros in the decimal part have
been omitted, which means we first generate a correct version of the
string, then trim it, then compare the roundtrip transformation to the
initial input.

The =collect (lengthOfDecimal s')= statement allows us to collect some
statistics about the distribution of the lenght of generated strings,
which unsurprisingly shows that lenght 7 (including the leading comma)
are vastly outnumbering other lengths, but those are not null:
<example>
90% 7.
8% 6.
0% 5.
0% 4.
0% 3.
</example>

The =0%= figures are due to some formatting issues of percentages in
Quickcheck. 

Given that we generated 10000 test cases without failures, we can now
be pretty confident that this part of the program is safe. We can have
some information about what part of the code we exercised using hpc:
<example>
ghc --make -fhpc -i/home/nono/soft/Calendar Accounting.hs QCTests.hs
hpc report QCTests
hpc markup QCTests
</example>

and here are the figures:
[[./hpc.png][HPC Html report]]
We can see that the coverage of Accounting module which contains the
main code is rather poor, which is normal as the quickcheck tests only
exercise a small part of the reading and parsing of numbers.

* 20080903: Projets au forfait

La [[http://docs.google.com/View?docid=dhk7xdkk_13f3nmntws][traduction]] d'un article de Scott Ambler sur les projets au forfait
dans lesquels toutes les variables sont fixées: prix, délais,
étendue. 

* 20080902: Maven reactor & dependency management

While working on a dependency management tool for Courtanet, I am
trying to understand how maven resolves things. Given a POM file for
some project, here are the following steps I could identify:
 - create a MavenProjet with a MavenProjectBuilder instance. The given
   project contains the read model, any relevant data constructed from
   profiles information and the Artifact inferred from the pom
 - resolve an artifact's transitive dependencies from a local repo and
   some remote repositories using =ArtifactCollector#collect()=
 - modules must be collected and their projects constructed
   "manually", walking through the modules sections, reading poms and
   adding their dependencies. This is what is done by =DefaultMaven= and
   =MavenEmbedder=
 - the parent's =Artifact= and =MavenProject= is added automatically when
   a project is read but this does not seem to be recursive: parent's
   =getArtifact= method returns null, so does =parent.getParentArtifact()=.
 - the problem seems to be that I need two different kind of things:
   =MavenProject= and =Artifact= instances. The former is constructed
   through *reading* some effective project description (ie. a file)
   while the latter is constructed through resolution mechanism, using
   ArtifactResolver and/or ArtifactCollector. The link between them is
   the =File= object:
    - from a MavenProject I can =getFile()= and =getArtifact()=
    - from an Artifact which is resolved I can =getFile()= and do something


* 20080901: Parsec experiments

Tried to do some handling of [[http://www.newartisans.com/software/ledger.html][ledger]]'s CSV output using Haskell's
[[http://legacy.cs.uu.nl/daan/parsec.html][parsec]] library. It took me a whole afternoon to manage to construct a
signle transaction item as I had lot of problems:
 - files contained UTF-8 characters that are not handled well by
   Haskell: I had to trim my examples down to remove those char
 - CSV is double-quoted and comma-separated, and currency values use
   comma as decimal separator. I had to figure how to express strings
   not containing double quotes, to find the error about commas in
   numbers
 - I forgot (!) commas between fields in the parsing, which obviously
   led to lot of errors

The resulting code is ugly, following closely my experiments and
progress in understanding Parsec's combinators. I suspect the time to
implement loading into database will be similar...

* 20080827: GTTSE 09 announced

Maybe I could propose a short or informal tutorial software
engineering practices that relates to generative programming:
 - development of embedded DSLs,
 - test generation with property based test tools like quickcheck,
   scalacheck and reductio

* 20080827: SPA Conference proposal

This workshop could easily be a 300' full tutorial for the Sunday
afternoon, or day-long workshop.

Title: More Bells and Whistles: Validating Code Beyond Unit Tests with
Functional Programming

One-line description: Exploring validation and verification of code
from an agile perspective with more than unit tests, or how can we
improve quality, simplicity, legibility using tools from the functional
programming paradigm ?

Session format:  150 Minutes Workshop/Tutorial

Abstract:
Test Driven Development is one cornerstone of eXtreme Programming and
its advantages are well-known: it guides developers, builds confidence
in the system and provides secure scaffolding to support change.
There are however some drawbacks in using this technique: it is quite
verbose, it places to much emphasis on details, on the 'how' instead of
the 'what', it produces more code that will need to be maintained and
is not very useful to non technical people.

In this session, we want to explore techniques that keep the spirit of
TDD while being more concise, provides a better abstract view of what
we want to achieve, and may sometimes be more legible. These
techniques are drawn from the functional programming languages tools
and techniques. Functional languages are getting more and more
attention and some of their characteristics may be useful in
increasing software quality.

This workshop will be a hands-on guided coding party using the pure,
lazy, statically typed language Haskell and providing introduction to
some tools and techniques. Examples in other languages (Java, Scala, Javascript) will also be
provided.

Its goal is to study and assess each of the following techniques and tools within
the framework of XP practices in order to go *beyond* standard code
quality improvement practices:
 - property-driven test generation with Quickcheck (http://www.cs.chalmers.se/~rjmh/QuickCheck/) and coverage
   assessment with hpc;
 - algebraic datatypes, type classes and polymorphism and how an
   advanced type system can improves the static safety of
   programs; 
 - simple equational reasoning or how to prove that one's functions
   work as expected, within some expected bounds.

Audience background:
 - deep interest for programming languages and coding practice: most
   of the workshop's time is dedicated to coding and exploration of
   languages,
 - interest for agile practices, more precisely XP coding practices
   and for improving one's own practices,
 - previous exposure to some functional programming language or, even
   better, Haskell definitely a plus.

Benefits of participating:
 - practical working on FP techniques and tools
 - FP are hype (sort of): What benefits could their use really
   provides in terms of quality ? communication ? simplicity ?
   feedback ?
 - Understanding sophisticated (ML style) type system and what are
   they useful for
 - Making things more abstract

Materials you'll provide:
 - source repository for programming examples and exercises
 - source of sessions material: extended software examples, more
   coding examples, documentation and references
 - Haskell cheat sheet and development environment setup guidelines
 - Session's summary handouts
 
Process:
 1. a "simple" yet realistic problem is presented: how to manage form/input validations in a uniform and legible way ?
 2. a solution is sketched in Haskell and needed infrastructure and
    process are set up,
 3. various kind of development techniques made possible with Haskell
    are introduced, explained and tried on this example, using part of
    the larger problem as motivation:
     1. TDD using property-based test case generation with QuickCheck,
     2. Proper composition of validations and definition of an
        expressive embedded DSL using (and abusing) the type system,
     3. proof of simple properties and complexity measures using
        formal reasoning on equations,
 4. applicability of each of this technique is assessed wrt to
    mainstream agile development practices

Detailed timetable:
  - 0-20': Introduction and form validation problem (20')
  - 20-30' : Process negotiation (10')
     - all coding shall be done in *Randori* mode as in an XP dojo:
       coding is done in pairs, with 5' slots, pilot of pair is
       replaced by copilot and new copilot replace the latter each slot,
     - participants can bring along their own laptop, a Mercurial
       repository will be shared
     - guidelines for setting up development environment will be
       provided 
  - 30-65' : First problem: using Quickcheck to define "high-level tests" (35')
     - 5' : introduction to quickcheck and the problem
     - 30': coding rounds
 - 65-100' :Second problem: advanced properties of the type system for static
   validation of expressions (35')
     - same format as first problem
 - 100-135' : Third problem: equational reasoning and complexity analysis with
   pure functions (35')
     - same format as first problem
 - 135-150' : Wrap-up, evaluation and conclusion (15')

Outputs:
 - the code produced during the session as a versionned repository
 - evaluation of the three techniques presented: applicability to
   mainstream development, links to other languages support

History:
I designed with Christophe
Thibaut an introductory session on functional programming languages
which has been presented at XP Day Paris and Agile 2008, and will be
presented at XP Days Benelux 2008. This session is a creation that
draws upon our experience on this theme, exploring more advanced topics.

Themes:
Technology
Practice

Session Leaders
Arnaud Bailly

* 20080825: Reviving Builder project

While writing script for extracting commit stats from Hg such that one
can produce a graph of volume change in a code base, I needed to
upgrade my [[http://www.oqube.com/projects/builder][builder]] tool which contains some classes for handling
programmatically in Java [[http://www.selenic.com/mercurial][Mercurial]] repositories. The code did not work
anmyore, if it has ever worked, a couple of tests failing. While
digging through [[http://commons.apache.org/jci/xref/index.html][JCI API]] I finally concluded that it would be better to
use standard tools provided by javax.tools.* package in Java 6.

As a side-effect, I was finally able to use [[http://javac.info][closure]] proposal for Java
and compile (mostly) functional java samples. This will allow me to
start studying Reductio and how it applies to some standard code base.

I plan to revive builder and quickly adding the two most needed tools:
 - a maven agent for building quickly maven projects (a command-line
   tool will be enough for now)
 - a test agent wrapping [[http://google-testar.sourceforge.net/][Testar]] or [[http://xircles.codehaus.org/projects/jtestme][JTestMe]] to provide selective testing
   and rapid feedback

* 20080825: Presentation of Spec#

 - superset of C#
 - static verification of contracts: pre/post conditions, boundaries
   of arrays, ...
 - explicit about design decisions and assumptions
 - Eiffel, JML
     - pre/post checked at runtimes
     - + static verification on types
 - refocus unit testing efforts, mechanical part of unit testing:
   boundary analysis means you don't have to write those tests
 - Pecs (?) : test generation, same engine as Spec#, can use
   contracts, extract test cases from the code

* 20080825: Phantom types

A type parameter used in a datatype declaration that does not appear
in the rhs (ie. in the constructors) but serve as a way to separate
various instances of the same types at compile time. Can be used to:
 - provide some DSL's terms with differentiation in order to restrict
   operations admissible in the language
 - provide some limited form of dependent type, as in the following
   snippet (from [[http://en.wikibooks.org/wiki/Haskell/Phantom_types][WikiBooks]]):
<src lang="haskell">
-- Peano numbers at the type level.
data Zero = Zero
data Succ a = Succ a
-- Example: 3 can be modeled as the type
-- Succ (Succ (Succ Zero)))

data Vector n a = Vector [a] deriving (Eq, Show)

vector2d :: Vector (Succ (Succ Zero)) Int
vector2d = Vector [1,2]

vector3d :: Vector (Succ (Succ (Succ Zero))) Int
vector3d = Vector [1,2,3]

-- vector2d == vector3d raises a type error
-- at compile-time, while vector2d == Vector [2,3] works.
</src>

* 20080825: SPA 2009 Session Proposal

Test Driven Development is one cornerstone of eXtreme Programming. The
red-green-refactor cycle is the smallest form of feedback the
developer can receive. The advantages of using TDD are well-known and
may be summarized as: first, it gives the developers a strong guidance on
what to do that together with the heartbeat nature of cycles provide
confidence and ultimately good code; second, it incrementally builds a
kind of scaffolding for software that gives strong assurance when one
needs to change anything in the system.

There are however some drawbacks in using this technique: it is quite
verbose, it places to much emphasis on details, on the 'how' instead of
the 'what', it produces more code that will need to be maintained and
is not very useful to non technical people (this problem arises most often
when trying to introduce the TDD practice as lot of managers, and all
customers, cannot easily appreciate the value it provides without
delving into code and may dismiss it as some mundane developer
practice that we can easily get rid of when in a hurry, while actually
it stands at the heart of XP).

In this session, we want to explore techniques that keep the spirit of
TDD: build incrementally a software's safety net, while being more
concise, provides a better abstract view of what we want to achieve,
and may sometimes be more legible. These techniques, drawn from the
vast array of formal methods and programming languages research and
development, are not new, but most often are confined in some
particular contexts, eg. embedded and human-life critical software,
research groups. 

We believe that two parallel movements we see are occuring in the
software development business may be signs that the time is ripe for
introducing more formal techniques in the mundane world of IT: the
widespread adoption of some core agile practices such as unit and
functional automated testing, driven by the need for better quality
software; and the rise in interest for functional programming
languages such as Scala, F#, Haskell or functional aspects of OO
languages: closures, value-objects, side-effect free computations.

We are thus proposing this workshop as an exploration into languages
and tools for better quality software, applied to some short yet
representative problems. This workshop will be a hands-on guided
coding party using Scala or Haskell language and providing
introduction to some tools:
 - continuous testing;
 - property-driven test generation with tools like Quickcheck,
   Scalacheck and Reductio;
 - algebraic and other complex type systems (beyond nominal type
   systems common in imperative codes) and how it can improves the static safety of
   programs; 
 - simple equational reasoning or how to prove that one's functions
   work as expected;
 - complexity evaluation in time and space, and how to hunt for memory
   leaks and inefficient code.

The goal of the workshop is to study each of these techniques and tools within
the framework of XP practices, in order to assert which, if any, could
supplement, complement or replace standard TDD practices.

This workshop could introduce some of the following features:
 - functional java as proposed in [[http://functionaljava.org/]] and based
   on the [[http://javac.info][BGGA]] closure proposal for Java (which may or most probably
   may not reach Java 7)
 - functional javascript as exemplified in jQuery and other modern
   javascript frameworks
 - scala-to-java bridges and the converse
 - haskell

* 20080724: Connectique disque mobile

Attention à la connectique des disques transportables, elle doit
résister aux épreuves d'un transport en sac à dos.

* 20080724: Corrections format trac pour muse

 - le nombre de guillemets simple pour l'*emphasis* et le *strong* est
   inférieur de 1 au nombre nécessaire
 - une ligne blanche surnuméraire dans les *examples* 
 - les sauts de ligne ne sont pas corrects

* 20080721: Dojo on Systems Thinking

System thinking is about modeling systems as variables (*observables*)
with constraints between them. More formally, a *dynamic system* is  a
set of differential equations defining the behavior of a set of
variables over time.

This kind of system can easily be represented as
labelled digraphs where each node is a variable and each edge is
labelled with some coefficient, the value of the variable at any point
in time being the sum of all its incoming edges coefficient time the
opposite's vertex value.

Equivalently, the system can be represented as a *square matrix* where
each row is a variable, with value in cell defining the coefficient
for the variable at this column.

We want to simulate the evolution of such a system, with a *discrete
time*: state of the system progresses in discrete equal time
increments. While the former representation is easier to understand,
the latter is better suited for easy calculation of the state of the
system, which is just matrix multiplication.

* 20080718: Haskell networking

Networking in Haskell is just as magic as actors: one it compiles,
chances are high that you end up with a running program.

<src lang="haskell">
-- a server that listen for connection on some socket then
-- dispatches the content to actors according to message id
main = do sock <- listenOn (PortNumber $ fromInteger 6789)
	  forever $ answer sock
	      where
	      answer sock = do (hdl, host, port)  <- accept sock
			       forkIO $ server hdl
</src>

* 20080717: First actors

Some experiments on actors and concurrency with Haskell. My first
actor program :
<src lang="haskell">
module Main where
import Control.Concurrent
import Control.Concurrent.Chan
import System.IO
    
-- simple messages
type Msg = String

-- an actor has an idea, an associated channel and some action
-- performed when receiving messages
data Actor = MkActor Int (Actor -> Msg -> IO ()) 

run :: Chan Msg -> Actor -> IO ()
run chan a@(MkActor id hdl)  = do msg <- readChan chan
				  hdl a msg
				  threadDelay 1000
 

handler :: Actor -> Msg -> IO ()
handler (MkActor id hdl) msg =  putStrLn $ "actor " ++ show id ++ ": handling " ++ msg

main = let
       channels = [ newChan | id <- [ 1 .. 10]]
       actors   = [ (MkActor id handler) | id <- [1 .. 10] ]
       -- read a command from stding
       -- xx some string
       command  = do line <- getLine
		     return $ splitL line
       splitL :: String -> (Int, String)
       splitL (x : ' ' : rest) = (read (x : ""), rest)
       splitL _                = (0,"")
       loop chans = do (i,s) <- command
		       case i of
			      0 -> return ()
			      x -> do writeChan (chans !! (x - 1)) s
				      loop chans
       in
       do -- create 10 channels
          chans <- sequence channels
	  -- create 10 runners
	  runs  <- mapM (forkIO . uncurry run) (zip chans actors)
	  -- loop over input line
	  loop chans
</src>

This program is definitely ugly, however, and does not do justice to
the terse style usually available in haskell. I still have some things
to understand when working in a monad. Channels and actors creation is
especially tricky:
 - I need to have channels available outside actors to communicate to them
 - but creating a channel is in IO so I must call =newChan= in a do
   construct to pass it to the actors

There should be a simpler way to assemble those things.

Something really extraordinary is that, once I managed to compile that
program, iet just **worked** as expected ! I had no previous exposure to
doing I/O within Haskell apart from whaat I have read, neither did I
have any clue about *Control.Concurrent.Chan*, but it was quite easy to
assemble things up.

This is a tribute to Haskell's type systems (and a bit of my own
experience) that prevents you from writing totally silly
expressions. At the very least, you have the assurance that your
program will run, may be not in the expected way, but it won't crash
haphazardly.

* 20080715: Comptabilité pour le code

 - unité de compte: ligne de code
 - compte de résultat:
    - chiffre d'affaires: stories livrées (dans le trunk)
    - produits finis: stories terminées non livrées (dans une branche)
    - en-cours de production: stories non terminées
    - provisions: bug fixes (provision pour dépréciation du code)
 - bilan actif:
    - stocks PF et en-cours: code non livré
    - immobilisations: totalité du code

* 20080715: Réinstallation serveur

 - l'hôte est minimal et héberge des instances de *vserver* sur un
   réseau interne =192.168.50.0= utilisant des interfaces virtuelles
   sur =eth0.1=. 
 - le NAT redirige les connexions vers les =vserver=

Nom  || IP || Utilisation || Port naté
public | 3 | serveur mail entrant et sortant | 25,993
web | 4 | serveur web public | 80
dev | 2 | serveur de développement | 443

 - installation BIND9 et configuration réseau local =oqube.net= sur IP
   =192.168.50.xxx=
 - création script =make-vserver.sh= pour création et ajout automatique
   des vservers dans le DNS

** Public

 - installation *postfix* avec TLS (communication dans un tunnel crypté)
   et SASL (authentification des utilisateurs à la connexion) 
 - installation *courier* pour récupération des mails par IMAP/S
 - installation *spamassassin* et récupération des journaux anti-spam de
   =www.oqube.com=
 - création utilisateur =nono=

**TODO**:
 - alias mails

** Web

 - installation *apache2*

** Dev

 - installation *apache2*, *mod_python*, *mod_ssl*
 - installation (et test) *sun-jdk6*
 - installation *mercurial*
 - installation *openssl*, configuration CA et =openssl.cnf=
 - transfert dépôts =hg= depuis =www.oqube.com=
 - configuration site =secure=  pour accès HTTPS et authentification
   forte par certificats cryptés: création fichier mots de passe,
   génération certificat, configuration apache2
 - création certificat pour =nono= et autres

* 20080821: Example of bad coding

An example method that constructs some UI object. The intent is
expressed as comments in the code:
<src lang="java">
    /**
     * Construction de l'etape(initialisation de la vue)
     * 
     * @param styleStep
     * @param styleContent
     */
    public FlexTable initialiseView(String styleStep, String styleContent) {
        // on la construit
        view = new FlexTable();
        view.setStyleName(styleStep);
        // 1. header
        view.setWidget(0, 0, buildHeader());
        // 2. contenu
        if (null == form) {
            form = initForm();
            form.setStyleName(styleContent);
        }
        view.setWidget(1, 0, form);
        // 3. footer
        if (hasFooter()) {
            displayFooter();
        }
        return view;
    }
</src>

We can rephrase it, hopefully in much more legible way thus:

<src lang="java">
    public FlexTable initialiseView(String styleStep, String styleContent) {
        FlexTable view = new FlexTable();
        view.setStyleName(styleStep);
        buildTableHeader(view,0);
        buildTableBody(view,1);
        if(hasFooter()) displayFooter(view);
        return view;
    }

    private void buildTableHeader(FlexTable view, int pos) {
        view.setWidget(pos, 0, buildHeader());
    }

    private void buildTableBody(FlexTable view, int pos) {
        if (null == form) {
            form = initForm();
            form.setStyleName(styleContent);
        }
        view.setWidget(pos, 0, form);
    }

    private void maybeDisplayFooter(FlexTable view,int pos) {
            view.setWidget(pos, 0, buildFooter());
            view.getCellFormatter().setStyleName(pos, 0, AbstractStyles.FOOTER);
    }
</src>

This is not perfect as we can see that, for example, =buildTableBody=
method initializes some form in the enclosing context while at the
same time modifying the passed =FlexTable= view.

* 20080820: Jeux de langages et test

** La tour de Babel

Ce court trajet nous a permis enfin de mettre en évidence l'importance de la
question du *discours* et son irréductibilité: on ne peut pas tout dire,
et sur ce dont on ne peut rien dire, il faut se résigner à ce
taire. Cette position centrale du discours, des niveaux de discours,
des métalangages est un leg du postmodernisme. Le sens n'est pas un
produit univoque consubstantiel à un discours et qui serait produit de
bout en bout par un locuteur, c'est une relation, un processus en
constante évolution. 

Le processus de développement d'un logiciel doit donc être envisagé

 - les logiciels sont nécessairement multi-langages (eg. HTML, XML,
   Javascript, Java pour une application web)
 - le discours qu'un logiciel représente est lui-même un langage
 - les langages - de programmation - sont en fait des métalangages
   permettant de produire de nouveaux langages adaptés à un certain
   univers de discours 
 - tout discours est nécessairement polysémique, son sens est autant
   produit par son auteur que par son lecteur
 - le discours est non-linéaire

* 20080820: Get Feedback

[[http://www.io.com/~wazmo/blog/archives/2008_08.html#000285]]

* 20080818: Agile 2008 - Compte-rendu

 - La conférence est **grosse** (pour ne pas dire **bouffie**): 1600
   personnes, [[http://www.agile2008.org/program.html][50 sessions]] par demi-journées, une vingtaine de thèmes
   différents en parallèle dont le sens n'est pas toujours évident (et
   qui se recoupent partiellement), 400 intervenants (soit 25% des
   participants)...
 - C'est voulu par le thème global de la conférence *Expanding Agile
   Horizons*. De nombreuses sessions sont consacrées à l'adaptation de
   l'agilité à des structures de grandes tailles, des organisations
   réparties, des projets de plusieurs dizaines ou centaines de
   personnes... 
 - Il est difficile de se retrouver, et encore plus de communiquer et
   d'échanger, l'espace est immense et il n'y a pas vraiment de lieu
   central où tout le monde se retrouve à part l'Open Jam qui permet
   de proposer des sessions sauvages. C'est un grand hall à colonnes
   avec des coins aux diverses ambiances aménagées (plage, salon,
   bar...) et des vidéo-projecteurs en accès libre

** Chansons Françaises

 - La *scène* "Chansons Françaises" est très confidentielle. Le premier
   jour, nous sommes 10 à la [[http://submissions.agile2008.org/node/890][première session]] d'Alexandre Boutin sur
   le passage de Yahoo à l'agilisme, et je ne participe pas
   à la suivante. La session d'Esther Derby sur
   [[http://submissions.agile2008.org/node/2980][Crossing Cultures]] est annulée faute de participants ce qui nous
   permet, à Emmanuel et moi, de retravailler sur le problème des
   [[http://online-judge.uva.es/p/v1/101.html][Blocs]] lui en Ruby et moi en Haskell. 
 - La session d'Yves Hanoulle sur le [[http://submissions.agile2008.org/node/788][Jeu de Direction]] a failli subir
   le même sort, n'était la participation *in extremis* de Portia Tung
   et Pascal Van Cauvemberghe. Nous serons finalement 6 ce qui est
   très peu, mais permettra de travailler quand même. Cette session
   utilise des Lego pour mettre en perspective différents modes de
   direction et d'organisation: un mode très directif (je joue le
   rôle du chef de projet qui donne des ordres et décide de tout),  un
   mode autogestionnaire, et un mode *référent*, où le chef de projet
   est présent mais ne donne aucune direction, juste du *feedback* si on
   lui demande. 
 - [[http://submissions.agile2008.org/node/3471][Ma session]] enfin n'attire que 4 personnes (c'est peu !) que je
   connais tous personnellement et avec lesquelles j'ai déjà
   discuté. Nous en profitons pour faire un rapide tour d'horizon du
   jeu des *lambda* et de la création du DSL de validation de formulaire
   (voir [[http://www.oqube.com/projects/xpday]]):
     - le jeu fonctionne, mais il n'est toujours pas pratique. Une
       solution [[http://www.bls-magnet.fr/site/index.php][magnétique]] serait intéressante, mais à quel prix ?
     - il faut revoir les règles pour qu'elles soient plus précises et
       non ambigües. 
     - la forme hexagonal est sympa, mais peu pratique pour la
       fabrication. Par contre, elle peut permettre de construire
       facilement des arbres radiaux si on ajoute des flèches sur les
       tuiles pour indiquer les orientations possibles
     - l'exemple est bien, mais il faudrait encore le rendre plus
       *compelling*. Je n'ai pas dérouler le discours qui va avec, ni
       fait le codage en direct comme j'avais prévu, donc évidemment,
       c'est moins classe...
     - il y aurait un deuxième jeu à faire, plus avancé qui serait
       centré sur les *types* et les problèmes de conception, quand le
       premier s'intéresserait plus aux bases fonctionnelles et à la
       compréhension du paradigme

** Autres sessions

 - La session [[http://submissions.agile2008.org/node/917][Mirror,  Mirror on the Wall... Why Me?]] était très
   intéressante, avec une douzaine de participants. Au travers de la
   métaphore de Blanche-Neige et les sept nains, son objectif est
   d'aborder le problème de l'intégration au sein d'une équipe de
   différentes personnalités. Le jeu permet de découvrir comment nous
   percevons ces personnalités, et comment améliorer nos relations
   avec elles. Il est inspiré des classifications de [[http://en.wikipedia.org/wiki/Myers-Briggs_Type_Indicator][Myer-Briggs]] et
   des [[http://www.belbin.com/][Rôles d'équipes de Belbin]].
 - [[http://submissions.agile2008.org/node/3853][Scale Back]] est une session *extrêmement* dynamisante grâce au talent
   de son animateur, Tobias Mayer. La méthode utilisée peut
   s'appliquer à plein de problèmes de *brainstorming*, à partir du
   moment où l'on dispose d'un groupe relativement nombreux (ici 26
   personnes). Le but en était de produire un slogan pour inciter à
   faire des logiciels plus petits, plus simples, en accord avec
   l'esprit initial de l'agilité et en opposition avec la tendance
   actuelle à l'agilisme forcené pour tous les projets, gros ou
   petits. Le résultat a été de produire la phrase suivante:
      Keep agile small because passionate, collaborating individuals
      produce simple solutions
 - *Programming with stars* est une série de défis réalisés en public et
   par binômes, une sommité du milieu s'associant à un "inconnu" pour
   réaliser différentes tâches de programmation en direct:
   refactoring, compréhension d'un code légataire, implantation
   TDD... Le tout sous l'oeil de juges dont la sévérité n'égale que la
   mauvaise foi et l'humour (Rachel Davies, Mike Hill et Robert
   Martin). C'est drôle, enlevé et certaines prestations sont vraiment
   brillantes, en particulier:
    - un refactoring en C++ par Michael Feathers utilisant la
      technique des *sensing variables* (voir
      [[http://www.artima.com/weblogs/viewpost.jsp?thread=170799]]) 
    - le développement en TDD d'un code pour supprimer des *frames* dans
      une vidéo en utilisant une interface *mock* pour tester la gestion
      de l'horloge. C'est eux qui gagnent la finale...
 - Je zappe une bonne partie du discours de Tom Cooper, ainsi que
   l'intégralité de celui de James Surowiecki sur la *Sagesse des Foules*.

** Dojos

 - un premier dojo est organisé le mercredi matin par un groupe de
   Brésilien dont [[http://www.dtsato.com/blog/2008/02/24/coding-dojo-sao-paulo-agile-2008/][Danilo Sato]], Hugo Corbucci et Mariana (qui parlent
   français et sont venus au dojo  de Paris début juillet). On y parle
   Ruby et il traite du problème des Blocs (cf. ci-dessus), c'est
   très intéressant comme d'habitude, et l'on s'apperçoit à la fin que
   l'on a perdu du temps à ne pas introduire les bonnes abstractions
   dès le départ et a vouloir faire du *codage*. 
 - j'organise un second dojo pour jeudi matin, consacré à Haskell. Le
   problème traité est le même, mais il sert plus d'introduction au
   langage pour ses participants: [[http://dannorth.net/][Dan North]], [[http://sirenian.livejournal.com/][Liz Keogh]], Mariana et
   Kim, le flot habituel des tranches de 5 minutes du randori est très
   bousculé, et c'est un peu mou, mais bon, pas mal  de choses
   intéressantes. Le résultat est évidemment bien plus compact qu'en
   Ruby, même si nous bénéficions de l'expérience de la veille. Sur
   l'idée de Dan, nous travaillons avec des référentiels Mercurial et
   des serveurs =hg serve= afin que chacun puisse utiliser sa machine et
   ses habitudes, tout en ayant le code versionné. J'imagine que l'on
   pourrait étendre ce principe en utilisant un serveur VNC pour
   pouvoir changer facilement l'affichage d'une machine à l'autre. 


* 20080807: Options in Java

A cool hack to have =Maybe= (or =Option=) wrapper in Java: http://stephan.reposita.org/archives/2008/08/06/for-hack-with-option-monad-in-java/

* 20080804: Agile 2008 - Day Zero

First real day at Agile 2008, starting with the [[http://tech.groups.yahoo.com/group/aa-ftt/][AA-FTT]]
workshop. Workshop was in [[http://en.wikipedia.org/wiki/Open_Space_Technology][OpenSpace]] format (sort of). I like this
format: much more dynamic, gives plenty of rooms for interaction,
surprises, works great with small rooms. I was both a bit tired and a
lot impressed by the attendance, comprised of highly renowned and
respected people in the agile testing community like [[http://www.exampler.com/blog/][Brian Marick]],
[[http://testobsessed.com/][Elizabeth Hendrickson]] and many others, so I did not contribute a lot.

Some topics I picked up through the workshop:
 - great deal of questioning about what really is testing, and whether
   FTDD using Automated UAT is really valuable. Not many convincing
   experiences out there, lot of people seems to be using agile tools
   to (eg. Fit) to write standard regression tests on *existing
   software*, not really to drive *requirements elicitations* or
   *specifications explorations*
 - lot of things about testing through UI, with demos on tools
   building on Selenium and/or Fit. 
 - talks about DSTLs, exemplified by [[http://storytestiq.solutionsiq.com/wiki/Main_Page][StoryTestIQ]] and [[http://code.google.com/p/robotframework/][RobotFramework]]:
   tests are written in a small and simple  **functional programming
   language**: one can define reusable tests as *lambda-abstractions*
   (eg. functions with parameters), and thus constructs higher-level
   tests throughs combination of lower-level tests. Then, the question
   is: why not use a real language ? are the tests really written by
   customers ? if this is a programming language, what is tool support
   (RF has a soon-to-be-released IDE, STIQ uses the browser to write
   tests) ? 
 - if this are DS(T)Ls, what is the grammar ? There does not seem to
   be restrictions in how one can combine things, so you mostly have a
   flow of tokens with substitution but not really a *grammar*. To have,
   one, you have to enforce rules like: I can only use =input name=
   function on a page where =name= is defined, which means you would
   need some sort of *typing* of pages, or at least distinguishing
   various pages contexts
 - some englightning talks by B.Marick and ??? about a *virtual
   machine* for tests or in another words, builtin support for test
   automation in the language/platform providing:
    - different modes of execution like batch/interactive
    - a protocol to allow communication between SUT and context
    - a way to define *context*
    - support for simulation
 - a long-winded discussion on the difference between
   examples/tests/specifications. 
 - [[http://www.poppendieck.com/people.htm][Tom Poppendieck]] just dropped in to take photographs at some point
   and made a comment about "talking about requirements are a sure
   sign that something wrong will happen"
 - [[http://www.bossavit.com/thoughts/][Laurent Bossavit]] talked about [[http://www.amazon.com/Essential-Systems-Analysis-Stephen-McMenamin/dp/0132879050][Essential System Analysis]] and how it
   should be promoted to agilists. There is this idea of some
   engineering process where you could devise requirements without
   reference to technology, something that seems a bit contradictory
   with agile core practices to me. Separation of concerns at the
   process level breaks *integrity* which is a property carefully build
   up by agile practices. As soon as you are thinking of requirements
   and code as 2 different things, you are trapped into thinking that
   you can write both separately (either in time or space).
 - Brian Marick last talk is about how the standard *idealist*
   communication model is wrong. Communication and meaning does not
   happen like the following: I have an idea, that I express in words,
   that I transmit to you, that you decode and then we share the
   idea. Cognition is a social process, and meaning is something that
   is *traded* or *exchanged*: words only have an exchange value but no
   usage value, or rather their usage value is their exchange value. 
 - Lots of people thinking/talking/working on defining/implementing
   various kind of languages for better comprehension between BAs and
   developers. Human language being inherently ambiguous, you need at
   some point in time a way to disambiguate things for the computer to
   run it.

* 20080723: Le héros post-moderne

J'ai commencé à m'intéresser à l'informatique à peu près au moment où
le cyberpunk, comme genre littéraire, naissait. 

Profondément enfoui dans mon subconscient se trouve
donc la conviction que l'informaticien est LE héros post-moderne, et
conséquemment que l'informatique, ou plus précisèment l'activité de
programmer des ordinateurs et aussi celle d'assembler des machines
qui lui est souvent associée, sont des activités, des processus,
éminemment post-modernes. 

Le héros post-moderne se méfie des grands récits, il est paranoïaque. 

Il est même parfois un peu schizophrène,
quand il lui arrive de détourner le système à ses propres fins, car
qui sait si ce n'est pas le système qui le détourne ? La matrice
n'est-elle pas que l'espace utilisateur d'un gigantesque OS, et en
déchirer le voile ne serait-il pas accéder à l'espace noyau ? Auquel
cas, l'envers du décor, c'est toujours un autre décor, et non pas la
réalité. 

Le héros post-moderne est profondément libertaire. Il n'aime pas
le pouvoir et n'apprécie les règles et les lois que lorsqu'elles sont
révocables à merci. Il peut adopter un mode de vie strict, voire
ascétique, dans un but de dépassement de soi, jamais par dévotion
envers une religion. 

Le héros post-moderne est Agile. Il est pragmatique dans sa pratique,
et idéaliste dans ses objectifs. Il évolue dans des
organisations qui sont idéalistes dans la pratique qu'elles imposent,
et pragmatiques dans les buts qu'elles poursuivent. 

Le héros post-moderne sait que la chair est triste, et il a lu
un peu trop de livres. Il n'en aime pas moins passionnément la vie et
la connaissance. 

Il sait que la révolution doit être souhaitée, mais qu'elles finissent
toutes dans le bain de sang et la dictature. Il institue donc des
micro-révolutions là où c'est possible, trace des lignes de fuite. Sa
stratégie est celle du rhizome. Son horizon la totalité du réel.

Le héros post-moderne aime XP car XP a été conçu par un héros
post-moderne, pour d'autres héros post-modernes. Il n'est pas un
solitaire et n'a aucune appétence pour l'érémitisme. Au contraire, il
recherche la compagnie de ses semblables, car il sait que le sens est
dans la relation aux autres, pas dans le solipsisme. 

Le héros post-moderne ne se désole pas de la récupération de ses
fétiches par la société spectaculaire, car il sait que c'est le lot de toute
chose, et la seule chose que sait faire le spectacle. Il est lui-même un
grand récupérateur, assembleur, bidouilleur, sampleur, mashupeur...
Nomade et pragmatique, il change de terrain de chasse quand l'herbe a
été trop remâchée.

Je ne suis pas ce héros, mais il ne me déplairait pas que je le
fusse. 

* 20080714: Installation serveur

** Vserver script

Created vserver creation script:


** DNS

Created zone files for =oqube.net=:
<example>
cat >> /etc/bind/db.oqube.net << EOF
$TTL 3h
oqube.net.  IN SOA  master.oqube.net. adminsys.oqube.net. (
        1   ; serial
        3h  ; refresh
        1h  ; retry 
        1w  ; expire
        1h ); negative cache TTL

oqube.net. IN NS master.oqube.net.

master.oqube.net. IN A 192.168.50.1
dev.oqube.net.    IN A 192.168.50.2
EOF
cat >> /etc/bind/db.192.168.50 << EOF
$TTL 3h
50.168.192.in-addr.arpa.  IN SOA  master.oqube.net. adminsys.oqube.net. (
        1   ; serial
        3h  ; refresh
        1h  ; retry 
        1w  ; expire
        1h ); negative cache TTL

50.168.192.in-addr.arpa. IN NS master.oqube.net.

1.50.168.192.in-addr.arpa. IN PTR master.oqube.net.
2.50.168.192.in-addr.arpa. IN PTR dev.oqube.net.
EOF
cat >> /etc/bind/named.conf << EOF
// zone files for oqube.net. virtual network
zone "oqube.net" {
        type master;
        file "/etc/bind/db.oqube.net";
};

zone "50.168.192.in-addr.arpa" {
        type master;
        file "/etc/bind/db.192.168.50";
};
EOF
</example>

* 20080712: Haskell

2008.07.12 19:42:58

Tried using [[http://projects.unsafeperformio.com/hpc/][hpc]]. Works nicely and generates clean if somewhat
unappealing coverage reports. Very simple to use, is integrated in
ghc6.8.2.


Tried installing [[http://www.cs.kent.ac.uk/projects/refactor-fp/hare.html][HaRE]] tool for Haskell Refactoring on Ubunte 7.10 with
ghc 6.6.1. Two libraries are needed for proper compilation of the
[[http://www.cs.kent.ac.uk/projects/refactor-fp/hare/HaRe_27032008.tar.gz][snapshot]]: 

<example>
#provide networking
sudo aptitude install libghc6-network-dev
# providing Control.Monad.State
sudo aptitude install libghc6-mtl-dev
</example>

Tried to use the tool on Controles.hs but failed to do anything:
 - =add project= fails on import of Control.Arrow
 - added libdghc6-src package to have the ghc sources
 - but parser chokes on some =ifdef= directive

Unit tests does not work either:
 - import HUnit is incorrect, should be =import Test.HUnit=
 - all test fail

* 20080703: Sur les jeux de langage

[[../services/agile/postmodern]] un article en cours

----

 - [[archive200806.muse][Archives to June 2008]]
 - [[archive200712.muse][Archives to December 2007]]
 - [[archive200612.muse][Archives to December 2006]]
 - [[archive200608.muse][Archives to August 2006]]
